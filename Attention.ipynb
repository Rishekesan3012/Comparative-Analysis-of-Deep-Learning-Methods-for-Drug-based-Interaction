{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO/QAAiZF34zuuETm7Xbx9v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0qOBelA4SiF","executionInfo":{"status":"ok","timestamp":1687619676030,"user_tz":-330,"elapsed":27761,"user":{"displayName":"sathvika pingali","userId":"10895195703655253343"}},"outputId":"ac9a034c-a234-4b98-ad6c-723e69f7b0fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Embedding, Concatenate, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Bidirectional, LSTM, Flatten, GlobalAveragePooling1D, Multiply\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import csv\n","import random\n","\n","\n","# Load data\n","data = []  # list of lists of the form [smiles, sequence, pKd]\n","\n","with open('drive/MyDrive/nlp (1)/dta_df.csv') as csvfile:\n","    reader = csv.reader(csvfile)\n","    next(reader)  # skip header\n","    for row in reader:\n","        triplet = []\n","        triplet.append(row[0])\n","        triplet.append(row[1])\n","        triplet.append(float(row[2]))\n","        data.append(triplet)\n","\n","random.shuffle(data)\n","\n"],"metadata":{"id":"jZVG8sj734DM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","# Separate data into inputs (SMILES and proteins) and labels\n","smiles = [triplet[0] for triplet in data]\n","proteins = [triplet[1] for triplet in data]\n","labels = [triplet[2] for triplet in data]\n","\n","# Split data into train and test sets\n","split = int(0.9 * len(smiles))\n","train_smiles = smiles[:split]\n","test_smiles = smiles[split:]\n","train_proteins = proteins[:split]\n","test_proteins = proteins[split:]\n","train_labels = labels[:split]\n","test_labels = labels[split:]\n","\n"],"metadata":{"id":"Jq2hgTKz4EBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize smiles\n","tokenizer_smiles = Tokenizer(char_level=True)\n","tokenizer_smiles.fit_on_texts(train_smiles)\n","vocab_size_smiles = len(tokenizer_smiles.word_index)\n","\n","train_sequences_smiles = tokenizer_smiles.texts_to_sequences(train_smiles)\n","train_padded_smiles = pad_sequences(train_sequences_smiles, truncating=\"post\", padding=\"post\", maxlen=85)\n","\n","test_sequences_smiles = tokenizer_smiles.texts_to_sequences(test_smiles)\n","test_padded_smiles = pad_sequences(test_sequences_smiles, truncating=\"post\", padding=\"post\", maxlen=85)\n","\n","# Tokenize proteins\n","tokenizer_proteins = Tokenizer(char_level=True)\n","tokenizer_proteins.fit_on_texts(train_proteins)\n","vocab_size_proteins = len(tokenizer_proteins.word_index)\n","\n","train_sequences_proteins = tokenizer_proteins.texts_to_sequences(train_proteins)\n","train_padded_proteins = pad_sequences(train_sequences_proteins, truncating=\"post\", padding=\"post\", maxlen=1200)\n","\n","test_sequences_proteins = tokenizer_proteins.texts_to_sequences(test_proteins)\n","test_padded_proteins = pad_sequences(test_sequences_proteins, truncating=\"post\", padding=\"post\", maxlen=1200)\n","\n","train_smiles_array = np.array(train_padded_smiles)\n","test_smiles_array = np.array(test_padded_smiles)\n","train_proteins_array = np.array(train_padded_proteins)\n","test_proteins_array = np.array(test_padded_proteins)\n","train_labels_array = np.array(train_labels, dtype = \"float32\")\n","test_labels_array = np.array(test_labels, dtype = \"float32\")"],"metadata":{"id":"7Gp7N08P4HmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Concatenate, Dot, Activation, Flatten, Dense\n","from tensorflow.keras.models import Model\n","\n","# Define input layers\n","input_smiles = Input(shape=(85,))\n","input_proteins = Input(shape=(1200,))\n","\n","# Embedding layers\n","embedding_dim = 128\n","vocab_size_smiles = len(tokenizer_smiles.word_index) + 1\n","vocab_size_proteins = len(tokenizer_proteins.word_index) + 1\n","\n","\n","embedding_smiles = Embedding(input_dim=vocab_size_smiles, output_dim=embedding_dim, input_length=85)(input_smiles)\n","embedding_proteins = Embedding(input_dim=vocab_size_proteins, output_dim=embedding_dim, input_length=1200)(input_proteins)\n","\n","# Bi-LSTM layers\n","lstm_units = 128\n","\n","lstm_smiles = Bidirectional(LSTM(units=lstm_units, return_sequences=True))(embedding_smiles)\n","lstm_proteins = Bidirectional(LSTM(units=lstm_units, return_sequences=True))(embedding_proteins)\n","\n","# Attention mechanism\n","attention = Dot(axes=[2, 2])([lstm_smiles, lstm_proteins])\n","attention = Activation('softmax')(attention)\n","\n","# Weighted sum\n","context = Dot(axes=[2, 1])([attention, lstm_proteins])\n","weighted_protein = Concatenate(axis=1)([context, lstm_smiles])\n","\n","\n","# Output layer\n","output = Dense(units=1, activation='linear')(weighted_protein)\n","\n","# Create model\n","model = Model(inputs=[input_smiles, input_proteins], outputs=output)\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='mean_squared_error')\n"],"metadata":{"id":"jozFkuTf8Om7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(\n","    min_delta=0.001, # minimium amount of change to count as an improvement\n","    patience=10, # how many epochs to wait before stopping\n","    restore_best_weights=True,\n",")\n","\n","history = model.fit([train_smiles_array, train_proteins_array], train_labels_array,\n","                    epochs = 100, batch_size = 256, validation_data = ([test_smiles_array, test_proteins_array], test_labels_array), callbacks = [early_stopping])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92Q5U7v09Ymy","executionInfo":{"status":"ok","timestamp":1687621770690,"user_tz":-330,"elapsed":833477,"user":{"displayName":"sathvika pingali","userId":"10895195703655253343"}},"outputId":"e61e365f-9e00-47fc-8687-7cdae6605ffa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","84/84 [==============================] - 39s 363ms/step - loss: 3.6677 - val_loss: 0.9115\n","Epoch 2/100\n","84/84 [==============================] - 29s 341ms/step - loss: 0.7914 - val_loss: 0.8118\n","Epoch 3/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.7169 - val_loss: 0.7592\n","Epoch 4/100\n","84/84 [==============================] - 28s 339ms/step - loss: 0.6875 - val_loss: 0.7401\n","Epoch 5/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6750 - val_loss: 0.7332\n","Epoch 6/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6717 - val_loss: 0.7367\n","Epoch 7/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6684 - val_loss: 0.7276\n","Epoch 8/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6670 - val_loss: 0.7261\n","Epoch 9/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6671 - val_loss: 0.7264\n","Epoch 10/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6674 - val_loss: 0.7380\n","Epoch 11/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6666 - val_loss: 0.7236\n","Epoch 12/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6659 - val_loss: 0.7238\n","Epoch 13/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6638 - val_loss: 0.7234\n","Epoch 14/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6635 - val_loss: 0.7277\n","Epoch 15/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6640 - val_loss: 0.7295\n","Epoch 16/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6634 - val_loss: 0.7232\n","Epoch 17/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6640 - val_loss: 0.7232\n","Epoch 18/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6643 - val_loss: 0.7305\n","Epoch 19/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6654 - val_loss: 0.7224\n","Epoch 20/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6634 - val_loss: 0.7348\n","Epoch 21/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6626 - val_loss: 0.7223\n","Epoch 22/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6645 - val_loss: 0.7281\n","Epoch 23/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6634 - val_loss: 0.7453\n","Epoch 24/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6630 - val_loss: 0.7222\n","Epoch 25/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6674 - val_loss: 0.7284\n","Epoch 26/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6635 - val_loss: 0.7241\n","Epoch 27/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6623 - val_loss: 0.7257\n","Epoch 28/100\n","84/84 [==============================] - 28s 337ms/step - loss: 0.6630 - val_loss: 0.7253\n","Epoch 29/100\n","84/84 [==============================] - 28s 338ms/step - loss: 0.6655 - val_loss: 0.7267\n"]}]},{"cell_type":"code","source":["loss = model.evaluate([test_smiles_array, test_proteins_array], test_labels_array)\n","print(\"Overall Loss:\", loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASzpewnr_MR4","executionInfo":{"status":"ok","timestamp":1687621789122,"user_tz":-330,"elapsed":5834,"user":{"displayName":"sathvika pingali","userId":"10895195703655253343"}},"outputId":"8f371ff6-2921-4405-e5b8-7c8bd1274231"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["75/75 [==============================] - 3s 42ms/step - loss: 0.7224\n","Overall Loss: 0.7223649621009827\n"]}]},{"cell_type":"code","source":["def predict_pKd(drug, protein):\n","  drug_sequence = tokenizer_smiles.texts_to_sequences([drug])\n","  drug_padded = pad_sequences(drug_sequence, truncating=\"post\", padding=\"post\", maxlen=85)\n","  protein_sequence = tokenizer_proteins.texts_to_sequences([protein])\n","  protein_padded = pad_sequences(protein_sequence, truncating=\"post\", padding=\"post\", maxlen=1200)\n","  prediction = model.predict([tf.expand_dims(drug_padded, axis=-1), tf.expand_dims(protein_padded, axis=-1)])\n","\n","  return prediction[0][0][0]  # Extract the single prediction value\n"],"metadata":{"id":"e1JizCpjGRY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drug = test_smiles[1520]\n","protein = test_proteins[1520]\n","label = test_labels[1520]\n","\n","print(label)\n","prediction = predict_pKd(drug=drug, protein=protein)\n","print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EFoBNxZsGVzK","executionInfo":{"status":"ok","timestamp":1687622069522,"user_tz":-330,"elapsed":5,"user":{"displayName":"sathvika pingali","userId":"10895195703655253343"}},"outputId":"91eb6ff5-3894-40e6-8559-a0c9307e6f98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5.721246399047171\n","1/1 [==============================] - 0s 64ms/step\n","5.438856\n"]}]}]}